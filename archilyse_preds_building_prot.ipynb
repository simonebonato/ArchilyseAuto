{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from nb_utils.archilyse_auto_utils import plot_predictions\n",
    "from nb_utils.archilyse_preds_building_prot import (\n",
    "    extract_building_from_path,\n",
    "    extract_site_from_path,\n",
    "    process_polygon,\n",
    ")\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ifc_dl.utils.io import load_pdf_ecolution\n",
    "\n",
    "BASE_FOLDER = Path(\"/ifc_dl\")\n",
    "\n",
    "archylise_path = BASE_FOLDER / \"submodules/ArchilyseAuto\"\n",
    "sys.path.append(str(archylise_path))\n",
    "\n",
    "from predictors.predictors.floorplans import FloorplanPredictor\n",
    "from predictors.predictors.icons import IconPredictor\n",
    "\n",
    "# from predictors.predictors.roi import RoiPredictor\n",
    "from predictors.predictors.spaces import SpacePredictor\n",
    "from predictors.predictors.walls import WallPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pdf to predict from in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = BASE_FOLDER / \"data/building_prototypes/hohbaÌˆchli_6_5079_zeihen/annotated/zeihen_annotated.pdf\"\n",
    "page_names = ['-1', '0', '1', 'section_a_b', 'sw_facade', 'nw_facade']  # by hand\n",
    "idx_to_consider = [0, 1, 2]\n",
    "\n",
    "pages_list = load_pdf_ecolution(pdf_path)\n",
    "pages_with_names = [(page_names[idx], pages_list[idx]) for idx in idx_to_consider]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "resources_path = archylise_path / \"resources\"\n",
    "\n",
    "wall_predictor = WallPredictor(str(resources_path / \"walls_model_latest.pth\"))\n",
    "space_predictor = SpacePredictor(str(resources_path / \"spaces_model_final.pth\"))\n",
    "\n",
    "icon_pred_version = 2  # 1 or 2\n",
    "\n",
    "version_str = \"\" if icon_pred_version == 1 else \"_2\"\n",
    "icon_weights_path = str(resources_path / (\"icons_model_final\" + version_str)) + \".pth\"\n",
    "icon_predictor = IconPredictor(icon_pred_version, icon_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the predictors to use to get the predictions\n",
    "predictors = {\n",
    "    \"space\": space_predictor,\n",
    "    \"icons\": icon_predictor,\n",
    "    \"walls\": wall_predictor,\n",
    "}\n",
    "\n",
    "# main loop for getting the predictions and saving them in a json file\n",
    "final_json = []\n",
    "for storey_name, page_dict in tqdm(pages_with_names):\n",
    "\n",
    "    img = page_dict['original_img']\n",
    "    page_info = page_dict['page_info']\n",
    "    px_per_m = np.mean([page_info['px_m_ratio_width'], page_info['px_m_ratio_height']])\n",
    "\n",
    "    img_dict = {}\n",
    "\n",
    "    # get the path from \"building_prototypes\"\n",
    "    starting_idx_path = pdf_path.parts.index(\"data\")\n",
    "    rel_path = \"/\".join(pdf_path.parts[starting_idx_path:])\n",
    "\n",
    "    img_dict = {\n",
    "        \"img_path\": rel_path,\n",
    "        \"coords\": page_info['coords'],\n",
    "        \"site\": extract_site_from_path(pdf_path),\n",
    "        \"building\": extract_building_from_path(pdf_path),\n",
    "        \"storey\": storey_name,\n",
    "    }\n",
    "\n",
    "    for predictor_name, predictor in predictors.items():\n",
    "        labels, polygons, confidences = FloorplanPredictor.predict(\n",
    "            predictor,\n",
    "            img,\n",
    "            roi=[\n",
    "                (0, 0, img.shape[1], img.shape[0])\n",
    "            ],  # roi is the whole image for the moment\n",
    "            pixels_per_meter=px_per_m,\n",
    "        )\n",
    "\n",
    "        labels_name_json, labels_value_json, polygons_json, confidences_json = (\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "        )\n",
    "\n",
    "        for label, poly, confidence in zip(labels, polygons, confidences):\n",
    "            if isinstance(poly, (MultiPolygon, Polygon)):\n",
    "                geometries = poly.geoms if isinstance(poly, MultiPolygon) else [poly]\n",
    "                for geom in geometries:\n",
    "                    labels_name_json.append(label.name)\n",
    "                    labels_value_json.append(label.value)\n",
    "                    polygons_json.append(process_polygon(geom))\n",
    "                    confidences_json.append(confidence)\n",
    "            else:\n",
    "                raise ValueError(\"Geometry is neither Polygon nor MultiPolygon.\")\n",
    "\n",
    "        # add the predictions for this predictor\n",
    "        img_dict[predictor_name] = {\n",
    "            \"label_values\": labels_value_json,\n",
    "            \"label_names\": labels_name_json,\n",
    "            \"polygons\": polygons_json,\n",
    "            \"confidences\": confidences_json,\n",
    "        }\n",
    "\n",
    "        plot_predictions(img, (labels, polygons, confidences), storey_name + ' : ' + predictor_name)\n",
    "\n",
    "    final_json.append(img_dict)\n",
    "\n",
    "    # save the predictions in a json file\n",
    "    save_folder = Path('/ifc_dl/output') / (extract_site_from_path(pdf_path) + '_predictions')\n",
    "    save_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(str(save_folder / \"sample_pred.json\"), \"w\") as f:\n",
    "        json.dump(final_json, f, indent=3)\n",
    "        print(\"The predictions have been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
